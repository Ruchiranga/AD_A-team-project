{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os.path\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>tt0000009</td>\n",
       "      <td>movie</td>\n",
       "      <td>Miss Jerry</td>\n",
       "      <td>Miss Jerry</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>45</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>tt0000147</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Corbett-Fitzsimmons Fight</td>\n",
       "      <td>The Corbett-Fitzsimmons Fight</td>\n",
       "      <td>0</td>\n",
       "      <td>1897</td>\n",
       "      <td>\\N</td>\n",
       "      <td>20</td>\n",
       "      <td>Documentary,News,Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>tt0000335</td>\n",
       "      <td>movie</td>\n",
       "      <td>Soldiers of the Cross</td>\n",
       "      <td>Soldiers of the Cross</td>\n",
       "      <td>0</td>\n",
       "      <td>1900</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Biography,Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>tt0000502</td>\n",
       "      <td>movie</td>\n",
       "      <td>Bohemios</td>\n",
       "      <td>Bohemios</td>\n",
       "      <td>0</td>\n",
       "      <td>1905</td>\n",
       "      <td>\\N</td>\n",
       "      <td>100</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571</td>\n",
       "      <td>tt0000574</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Story of the Kelly Gang</td>\n",
       "      <td>The Story of the Kelly Gang</td>\n",
       "      <td>0</td>\n",
       "      <td>1906</td>\n",
       "      <td>\\N</td>\n",
       "      <td>70</td>\n",
       "      <td>Biography,Crime,Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tconst titleType                   primaryTitle  \\\n",
       "8    tt0000009     movie                     Miss Jerry   \n",
       "145  tt0000147     movie  The Corbett-Fitzsimmons Fight   \n",
       "332  tt0000335     movie          Soldiers of the Cross   \n",
       "499  tt0000502     movie                       Bohemios   \n",
       "571  tt0000574     movie    The Story of the Kelly Gang   \n",
       "\n",
       "                     originalTitle  isAdult startYear endYear runtimeMinutes  \\\n",
       "8                       Miss Jerry        0      1894      \\N             45   \n",
       "145  The Corbett-Fitzsimmons Fight        0      1897      \\N             20   \n",
       "332          Soldiers of the Cross        0      1900      \\N             \\N   \n",
       "499                       Bohemios        0      1905      \\N            100   \n",
       "571    The Story of the Kelly Gang        0      1906      \\N             70   \n",
       "\n",
       "                     genres  \n",
       "8                   Romance  \n",
       "145  Documentary,News,Sport  \n",
       "332         Biography,Drama  \n",
       "499                      \\N  \n",
       "571   Biography,Crime,Drama  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists('./filtered_movies.pkl'):\n",
    "    movies = pd.read_pickle(\"./filtered_movies.pkl\")\n",
    "else:\n",
    "    title_basics = pd.read_csv(\"data/title.basics.tsv\", sep='\\t')\n",
    "    movies = title_basics[title_basics.titleType == 'movie']\n",
    "    movies.to_pickle(\"./filtered_movies.pkl\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534354"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_url = 'https://www.imdb.com/title/'\n",
    "urls=[]\n",
    "for index, row in movies[:50].iterrows():\n",
    "    urls.append(base_url + row['tconst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |=: 'set' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-be93589c365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mall_links\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mget_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |=: 'set' and 'list'"
     ]
    }
   ],
   "source": [
    "all_links = set()\n",
    "for link in urls:\n",
    "    all_links |= get_links(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    scraped_data = {\n",
    "    \"tconst\": [],\n",
    "    \"stars\": [],\n",
    "    \"oscarWins\": [],\n",
    "    \"nominations\": [],\n",
    "    \"wins\": [],\n",
    "    \"releaseDate\": [],\n",
    "    \"releaseCountry\": [],\n",
    "    \"plotKeywords\": [],\n",
    "    \"budget\": [],\n",
    "    \"worldwideGross\": [],\n",
    "    \"metascore\": [],\n",
    "    \"musicProducer\": []\n",
    "    }\n",
    "    \n",
    "    info=[]\n",
    "    r = get(url)\n",
    "    page_body = r.text\n",
    "    soup = BeautifulSoup(page_body, 'html.parser')\n",
    "    \n",
    "    #tconst\n",
    "    \n",
    "    tconst=url.rsplit('/', 1)[-1]\n",
    "    scraped_data['tconst'].append(tconst)\n",
    "    # Stars\n",
    "    stars = []\n",
    "    stars_h4 = soup.find('h4', string='Stars:')\n",
    "    if stars_h4 is not None:\n",
    "        star_atags_parent = stars_h4.parent\n",
    "        if star_atags_parent is not None:\n",
    "            star_atags = star_atags_parent.find_all('a')\n",
    "            if star_atags is not None:\n",
    "                for atag in star_atags:\n",
    "                    if atag['href'].startswith('/name/'):\n",
    "                        stars.append(atag['href'].split('/')[2])\n",
    "    scraped_data['stars'].append(stars)\n",
    "    \n",
    "    \n",
    "    # Metascore\n",
    "    metascore = None\n",
    "    metascore_list = soup.select('.metacriticScore span:first-child')\n",
    "    if len(metascore_list) > 0:\n",
    "        metascore = metascore_list[0].string\n",
    "        \n",
    "    scraped_data['metascore'].append(metascore)\n",
    "    \n",
    "    \n",
    "    #awards\n",
    "    awrds_lines = soup.find_all(class_=\"awards-blurb\")\n",
    "    oscars = 0\n",
    "    wins = 0\n",
    "    nominations = 0\n",
    "    for line in awrds_lines:\n",
    "        \n",
    "        if line.findChild() is not None:\n",
    "            prepped_str = re.sub(' +', ' ', line.findChild().text.replace(\"\\n\", \" \").strip())\n",
    "            res = re.search('(W|w)on (\\d+) (O|o)scars.?', prepped_str)\n",
    "            if res is not None:\n",
    "                oscars = int(res.group(2))\n",
    "            \n",
    "        else:\n",
    "            prepped_str = re.sub(' +', ' ', line.text.replace(\"\\n\", \"\").strip())\n",
    "            \n",
    "            res = re.search('(\\d+) wins', prepped_str)\n",
    "            if res is not None:\n",
    "                wins = int(res.group(1))\n",
    "            \n",
    "            \n",
    "            res = re.search('(\\d+) nominations', prepped_str)\n",
    "            if res is not None:\n",
    "                nominations = int(res.group(1))\n",
    "    scraped_data['oscarWins'].append(oscars)\n",
    "    scraped_data['wins'].append(wins)\n",
    "    scraped_data['nominations'].append(nominations)\n",
    "    \n",
    "    \n",
    "    # Release date\n",
    "    release_date_h4 = soup.find('h4', string='Release Date:')\n",
    "    release_date = None\n",
    "    release_country = None\n",
    "    if release_date_h4 is not None:\n",
    "        release_date_raw_text = release_date_h4.parent.findAll(text=True, recursive=False)\n",
    "        release_date_prepped = re.sub(' +', ' ', ''.join(release_date_raw_text).replace(\"\\n\", \"\").strip())\n",
    "        date_str_match = re.search(r'\\d{1,2} \\w+ \\d{4}', release_date_prepped)\n",
    "        if date_str_match is not None:\n",
    "            release_date = datetime.strptime(date_str_match.group(), '%d %B %Y').date()\n",
    "        release_country_match = re.search(r'\\(([a-zA-Z ]{2,})\\)', release_date_prepped)\n",
    "        if release_country_match is not None and len(release_country_match.groups()) > 0:\n",
    "            release_country = release_country_match.group(1)\n",
    "        \n",
    "    scraped_data['releaseDate'].append(release_date)\n",
    "    scraped_data['releaseCountry'].append(release_country)\n",
    "    \n",
    "    \n",
    "    # Budget\n",
    "    budget_h4 = soup.find('h4', string='Budget:')\n",
    "    budget = None\n",
    "    if budget_h4 is not None:\n",
    "        budget_raw_text = budget_h4.parent.findAll(text=True, recursive=False)\n",
    "        budget = re.sub(' +', ' ', ''.join(budget_raw_text).replace(\"\\n\", \"\").strip())\n",
    "        \n",
    "    scraped_data['budget'].append(budget)\n",
    "    \n",
    "    \n",
    "    # worldwide gross\n",
    "    gross_h4 = soup.find('h4', string='Cumulative Worldwide Gross:')\n",
    "    gross = None\n",
    "    if gross_h4 is not None:\n",
    "        gross_h4_text = gross_h4.parent.findAll(text=True, recursive=False)\n",
    "        gross = re.sub(' +', ' ', ''.join(gross_h4_text).replace(\"\\n\", \"\").strip())\n",
    "    \n",
    "    scraped_data['worldwideGross'].append(gross)\n",
    "    \n",
    "    \n",
    "    # Plot keywords\n",
    "    keywords_verification_threshold = 2 # Consider only words atleast 2 people considered relavent\n",
    "    keywords_url = url + \"/keywords\"\n",
    "    r = get(keywords_url)\n",
    "    page_body = r.text\n",
    "    soup = BeautifulSoup(page_body, 'html.parser')\n",
    "    keywords = []\n",
    "    plot_keywords_items = soup.find_all(class_=\"soda sodavote\")\n",
    "    if plot_keywords_items is not None:\n",
    "        for plot_keywords_item in plot_keywords_items:\n",
    "            validity_text = plot_keywords_item.find(class_='interesting-count-text').a.text.strip()\n",
    "            validity_text_match = re.search(r'(\\d+) of', validity_text)\n",
    "            if validity_text_match is not None and len(validity_text_match.groups()) > 0:\n",
    "                if int(validity_text_match.group(1)) >= keywords_verification_threshold:\n",
    "                    keywords.append(plot_keywords_item.find(class_='sodatext').a.text.strip())\n",
    "    \n",
    "    scraped_data['plotKeywords'].append(keywords)\n",
    "    \n",
    "    \n",
    "    # Music producer\n",
    "    fullcredits_url = url + \"/fullcredits\"\n",
    "    r = get(fullcredits_url)\n",
    "    page_body = r.text\n",
    "    soup = BeautifulSoup(page_body, 'html.parser')\n",
    "    \n",
    "    music_producer = None\n",
    "    \n",
    "    full_credits_container = soup.find(id='fullcredits_content', class_='header')\n",
    "    if full_credits_container is not None:\n",
    "        full_credits = full_credits_container.find_all(recursive=False)\n",
    "        if full_credits is not None:\n",
    "            for idx, item in enumerate(full_credits, start=0):\n",
    "                if 'Music by' in item.text:\n",
    "                    producer_atag = full_credits[idx + 1].find('a')\n",
    "                    if producer_atag is not None:\n",
    "                        producer_href = producer_atag['href']\n",
    "                        if producer_href is not None:\n",
    "                            music_producer = producer_href.split('/')[2]\n",
    "                            break\n",
    "    \n",
    "    scraped_data['musicProducer'].append(music_producer)\n",
    "    return scraped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Pool(10)\n",
    "start = time.time()\n",
    "with Pool(5) as p:\n",
    "    data=p.map(get_data,urls)\n",
    "    p.terminate()\n",
    "    p.join()\n",
    "end = time.time()\n",
    "print('Time taken: %f seconds' % (end - start) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.DataFrame(data=data)\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_links"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
